---
lang: fr
lang-ref: ch.15-1
title: Méthodes d'enchâssements joints contrastives
lecturer: Alfredo Canziani et Jiachen Zhu
authors: Sai Charitha Akula
date: 12 May 2022
translation-date: 20 Jul 2022
translator: Loïck Bourdois
---

<!---
## Visual Representation Learning

Representation learning trains a system to produce the representations required for feature detection or classification from raw data. Visual representation learning is about the representations of images or videos in particular.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig1.png" width="75%"/><br>
<b>Fig. 1</b>: Visual Representation Learning
</center>

This can be broadly classified as shown above and the focus of the lecture would be on self-supervised visual representation learning.
---->


## Apprentissage de représentations visuelles

L’apprentissage de représentation consiste à entraîner un système à produire des représentations, pour la détection de caractéristiques ou pour la classification, à partir de données brutes. L'apprentissage de représentations visuelles concerne les représentations d'images ou de vidéos en particulier.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig1.png" width="75%"/><br>
<b>Figure 1 :</b> Apprentissage de représentations visuelles
</center>

On peut les classer comme indiqué ci-dessus et ce qui suit portera essentiellement sur l'apprentissage autosupervisé de représentation visuelle.

<!---
## Self-supervised Visual Representation Learning

It is a two stage process comprising pretraining and evaluation

##### Step1: Pretraining

Uses a large amount of unlabeled data to train a backbone network. Different methods will produce the backbone network differently

##### Step2: Evaluation

It can be performed in two ways: feature extraction and finetuning. Both these methods generate representation from the image and then use it to train DsTH ( Downstream Task Head ). The learning of the downstream task would thus be in the representation space instead of the image space. The only difference between the two methods is the stop gradient before the encoder. In finetuning, we can change the encoder unlike in feature extraction.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig2.png" width="40%"/><br>
<b>Fig. 2</b>: Self-supervised Visual Representation Learning
</center>
---->


## Apprentissage autosupervisé de représentations visuelles

Il s'agit d'un processus en deux étapes comprenant un pré-entraînement et une évaluation.

##### Etape 1 : pré-entraînement

Utilisation d'une grande quantité de données non étiquetées pour entraîner un réseau *backbone*. Différentes méthodes produiront le *backbone* différemment.

##### Etape 2 : évaluation

Elle peut être réalisée de deux manières : l'extraction de caractéristiques et le *finetuning*. Ces deux méthodes génèrent une représentation à partir de l'image et l'utilisent ensuite pour entraîner la tête de tâche en aval (DsTH pour *Downstream Task Head*). L'apprentissage de la tâche en aval se fait donc dans l'espace de représentation au lieu de l'espace d'image. La seule différence entre ces deux méthodes est l'arrêt du gradient avant l'encodeur. Dans le *finetuning*, nous pouvons changer l'encodeur, contrairement à l'extraction de caractéristiques.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig2.png" width="40%"/><br>
<b>Figure 2 :</b> Apprentissage autosupervisé de représentations visuelles
</center>


<!---
### Generative Models

The popular one is the denoising autoencoder. You train the model to reconstruct the original image from the noisy image. After the training, we retain the encoder for the downstream task.

##### Issues:

The model tries to solve a problem that is too hard. For example: For a lot of downstream tasks, you don't have to reconstruct the image, which is a tougher problem than the downstream task itself. Also, sometimes the loss function is not good enough. For example: the Euclidean distance used as a reconstruction loss metric isn’t a good metric for comparing the similarity between two images.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig3.png" height="75%" weight="75%"/><br>
<b>Fig. 3</b>: Generative Models - Autoencoder
</center>
---->

### Modèles génératifs

Le plus Populaire est l’auto-encodeur débruiteur. On entraîne le modèle à reconstruire l’image originale à partir de l’image bruitée. Après l’entraînement, on réentraîne l’encodeur pour la tâche en aval.

##### Problèmes

Le modèle tente de résoudre un problème qui est trop difficile. Par exemple, pour beaucoup de tâches en aval, il ne faut pas reconstruire l'image qui est un problème plus complexe que la tâche en aval elle-même. De même, il arrive que la fonction de perte ne soit pas assez bonne. Par exemple, la distance euclidienne utilisée comme métrique de perte de reconstruction n'est pas une bonne métrique pour comparer la similarité entre deux images.
<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig3.png" height="75%" weight="75%"/><br>
<b>Figure 3 :</b> Modèles génératifs, l’auto-encodeur
</center>


<!---
### Pretext Tasks

It’s almost the same as above but you train the model to figure out a smart way to generate pseudo labels. For example: Given the image of a tiger, the shuffled image is the input x, and the output y would be the correct way of labeling the patches. The network successfully reinventing the patches indicates that it understands the image.

##### Issues:
Designing the pretext task is tricky. if you design the task too easy, the network won’t learn good representation. But if you design the task hard, it can become harder than the downstream task and the network wouldn't be trained well. Also, the representations generated via this method will be tailored to the specific downstream task.

<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig4.png" height="75%" weight="75%"/><br>
<b>Fig. 4</b>: Pretext Tasks
</center>
---->

### Tâches de prétexte

C'est presque la même chose que ci-dessus mais on entraîne le modèle à trouver un moyen intelligent de générer des pseudo-étiquettes. Par exemple, étant donné l'image d'un tigre, l'image mélangée est l'entrée x et la sortie y serait la bonne manière d'étiqueter les patchs. Le fait que le réseau réussisse à réinventer les patchs indique qu'il comprend l'image.

##### Problèmes

La conception de la tâche de prétexte est délicate. Si vous la concevez trop facile, le réseau n'apprendra pas une bonne représentation. Mais si vous la concevez trop difficile, elle peut devenir plus difficile que la tâche en aval et le réseau ne sera pas bien entraîné. En outre, les représentations générées par cette méthode seront adaptées à la tâche spécifique en aval.
<center>
<img src="{{site.baseurl}}/images/week15/15-2/2_fig4.png" height="75%" weight="75%"/><br>
<b>Figure 4 :</b> Tâches de prétexte
</center>


<!---
## Joint Embedding Methods

Joint Embedding methods try to make their backbone network robust to certain distortions and are invariant to data augmentation.

As an example, as shown in the image below, for an image of a dog, you take two distorted versions of the image, then encode them with your backbone network to generate representations and you make them to be close to each other. Thus, ensuring the two images share some semantic information.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig0.png" width="50%"/><br>
<b>Fig. 1</b>: Data Augmentation in JEM
</center>

They also prevent trivial solutions. The network could collapse with just the above condition, as the network can become invariant not only to distortions but to the input altogether i.e., irrespective of the input, it could generate the same output. JEMs try to prevent this trivial solution in different ways.

Instead of considering only local energy ( between two pairs of distorted images ), these methods get a batch of the images and ensure that the collection of the representation, $\green{H}_{\vx}$, doesn’t have the same rows or columns. ( which is the trivial solution )

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig1.png" width="50%"/><br>
<b>Fig. 2</b>: Preventing Trivial Solutions in JEM
</center>
---->

## Les méthodes d'enchâssements joints

Les méthodes d'enchâssements joints tentent de rendre leur *backbone* robuste à certaines distorsions et invariant à l'augmentation des données.

Par exemple, comme le montre l'image ci-dessous, pour l'image d'un chien, vous prenez deux versions déformées de l'image, puis vous les passez dans les *backbones* pour générer des représentations et vous faites en sorte qu'elles soient proches les unes des autres. Ainsi, vous vous assurez que les deux images partagent certaines informations sémantiques.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig0.png" width="50%"/><br>
<b>Figure 5 :</b> Augmentation de données en JEM
</center>

Le réseau pourrait s'effondrer avec la seule condition ci-dessus car il peut devenir invariant non seulement aux distorsions mais aussi à l'entrée dans son ensemble, c'est-à-dire que, quelle que soit l'entrée, il pourrait générer la même sortie. Les JEMs essaient d'empêcher cette solution triviale de différentes manières.

Au lieu de considérer uniquement l'énergie locale (entre deux paires d'images déformées), ces méthodes ont un batch d'images et s'assurent que la collection de la représentation, $\green{H}_{\vx}$, n'a pas les mêmes lignes ou colonnes (ce qui correspond à la solution triviale).

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig1.png" width="50%"/><br>
<b>Figure 6 :</b> Empêcher les solutions triviales dans les JEMs
</center>

D est l'énergie qui est calculée par échantillon. A et B sont les fonctions de perte qui sont calculées pour les batchs de taille N. L'opérateur en pointillé est pour l'empilement. $h_x$, $h_y$ sont les représentations de $x$, $y$ et $H_x$ et $H_y$ sont les matrices avec chaque ligne de $h_x$ et $h_y$.


<!---
### Components:

Every Joint Embedding Method has the following components:

1. Data augmentation ( $\vx$ and $\vy$ ): The way you generate the two distorted versions of the image.
2. Backbone Network ( $\lavender{BB}$ ) - The definition of the backbone
3. Energy function ( $\red{D}$ ) - The definition of the distance between the two representations.
4. Loss functionals ( $\green{A}$ and $\green{B}$ ) - The definition of the loss functionals calculated per batch of size N.
---->

### Composants :

Chaque méthode d’enchâssements joints a les composantes suivantes :

1. Augmentation des données ($\vx$ et $\vy$) : la façon dont vous générez les deux versions déformées de l'image.
2. Le *backbone* ($\lavender{BB}$) : la définition du *backbone*.
3. La fonction d'énergie ($\red{D}$) : la définition de la distance entre les deux représentations.
4. Les fonctions de perte ($\green{A}$ et $\green{B}$) : la définition des fonctions de perte calculées par batch de taille N.


<!---
### Joint Embedding Loss Functions:

Joint Embedding Loss Functions contain two components:
1. A term that pushes the positive pair closer
2. An (implicit) term that prevents the trivial solution (constant output) - implicit because a lot of "other methods" do not have an explicit term to prevent the trivial solution.

To make the training stable, people usually normalize the embeddings or put a hinge on the loss function to prevent the norm of embeddings from becoming too large or too small.
---->

### Fonctions de perte des méthodes d’enchâssements joints :

Les fonctions de perte des méthodes d’enchâssements joints contiennent deux composantes :
1. Un terme qui rapproche la paire positive
2. Un terme (implicite) qui empêche la solution triviale (sortie constante). Le terme est implicite car beaucoup d'« autres méthodes » n'ont pas de terme explicite pour empêcher la solution triviale.

Pour rendre l’entraînement stable, les gens normalisent généralement les enchâssements ou mettent un seuil sur la fonction de perte pour empêcher la norme des enchâssements de devenir trop grande ou trop petite.


<!---
### Training Methods

The training methods can be further classified into the following four types:
1. Contrastive methods
2. Non-Contrastive methods
3. Clustering methods
4. Other methods

We now go into the details of each of these methods
---->

### Méthodes d’entraînement

Les méthodes d’entraînement peuvent être classées en quatre types différents :
1. Les méthodes contrastives
2. Les méthodes non-contrastives
3. Les méthodes de regroupement (*clustering*)
4. Les « autres méthodes »


<!---
### Contrastive methods

Contrastive methods push positive pairs closer and negative pairs away. More details about the contrastive methods including MoCo, PIRL, and SimCLR have been discussed [here](https://atcold.github.io/NYU-DLSP20/en/week08/08-1/).


#### The InfoNCE loss function:
Both SimCLR and MoCo use the InfoNCE loss function.

$$
\red{L}(\boldsymbol{w},\vx,\vy) = \\[0.5cm]
= -\text{log} \frac{\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} )  ) }
{ \sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} )) +
\sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ))  } \\[0.5cm]

= -\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} ) + \text{log} \Big[
    \sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} )) +
\sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ))  ]\\[0.5cm]

= -\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} ) + \text{softmax}_\blue{\beta} [
     \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} ),
 \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ) ] \\[0.5cm]

\text{sim} (\green{h_{\vx}}, \green{h_{\vy}} ) = \frac{ \green{h_{\vx}}^\top \green{h_{\vy}} } { ||\green{h_{\vx}} || \, ||\green{h_{\vy}} ||  }

$$


The first term indicates the similarity between positive pairs and the second term is the softmax between all the negative pairs. We would like to minimize this whole function.

Notice that it gives different weights to different negative samples. The negative pair that has high similarity is pushed much harder than the negative pair with low similarity because there's a softmax. Also, the similarity measurement here is the inner product between the two representations, and to prevent the gradient explosion, the norm is normalized. Thus, even if the vector grew long, the term ensures that it is a unit vector.

#### Memory Bank:

As already mentioned, these models require negative samples. However, finding negative pairs becomes difficult as the embedding spaces become large.

To handle this, SimCLR and MoCo use large batch sizes to find the samples. The difference between SimCLR and MoCo is the way they deal with the large batch size. SimCLR uses 8192 as the batch size. However, MoCo tries to solve the requirement of a large batch size without actually using a large batch size by using a memory bank. It uses a small batch size but instead of using negative samples from only the current batch, it collects them even from previous batches. For example: with a 256 batch size, aggregating the previous 32 batches of negative samples results essentially in a batch size of 8192. This method saves memory and avoids the effort to generate the negative samples again and again.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig3.png" height="75%" width="75%"/><br>
<b>Fig. 4</b>: Memory Bank
</center>

Issue:
Because B is updated every step, the backbone is updated every step, and thus, after a while, the old negative samples are not valid anymore and can lead to a decrease in performance. To avoid this, MoCo uses a momentum backbone that slows down the training of the right backbone. In that case, the difference between the older momentum backbone and the new momentum backbone is not that different, retaining the validitiy of the negative sample even after a while.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig4.png" height="75%" width="75%"/><br>
<b>Fig. 5</b>: Memory Bank with Momentum Backbone
</center>

$\vartheta_{t+1}$ ( momemtum backbone’s parameter ) is an exponential moving average of $\theta_{t}$. The learning rate of $\vartheta$ is $( 1 -  m )* \eta$. High values of $m$ will make the $\vartheta_{t}$ stable. $m$ =1 will make $\vartheta_{t}$  basically untrained. If $m$ is very small like 0, $\vartheta_{t+1}$ is $\theta_{t+1}$.

$$
\theta_{t+1} = \theta_{t} - \eta\Delta\theta_{t}  \\
\vartheta_{t+1} = m\vartheta_{t} + ( 1- m )\theta_{t+1}
$$

<div style="text-align: center">
$\theta:$ backbone parameters
</div>

<div style="text-align: center">
$\vartheta:$ momentum backbone parameters
</div>


#### Disadvantages of Contrastive methods:

In practice, people found out that contrastive methods need a lot of setup to make them work. They require techniques such as weight sharing between the branches, batch normalization, feature-wise normalization, output quantization, stop gradient, memory banks etc.,.This makes it hard to analyze. Also, they are not stable without the use of those techniques.
---->

### Méthodes contrastives

Les méthodes contrastives rapprochent les paires positives et éloignent les paires négatives. Plus de détails sur les méthodes contrastives, y compris MoCo, PIRL et SimCLR, sont disponibles dans l’[édition 2020 du cours](https://atcold.github.io/NYU-DLSP20/fr/week08/08-1/).


#### La fonction de perte InfoNCE :
SimCLR et MoCo utilisent tous deux la fonction de perte InfoNCE.

$$
\red{L}(\boldsymbol{w},\vx,\vy) = \\[0.5cm]
= -\text{log} \frac{\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} )  ) }
{ \sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} )) +
\sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ))  } \\[0.5cm]

= -\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} ) + \text{log} \Big[
    \sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} )) +
\sum_{\red{n}}^{N}\exp(\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ))  ]\\[0.5cm]

= -\blue{\,\beta\,} \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}} ) + \text{softmax}_\blue{\beta} [
     \text{sim} ( \green{h_{\vx}}, \green{h_{\vx}^\red{n}} ),
 \text{sim} ( \green{h_{\vx}}, \green{h_{\vy}^\red{n}} ) ] \\[0.5cm]

\text{sim} (\green{h_{\vx}}, \green{h_{\vy}} ) = \frac{ \green{h_{\vx}}^\top \green{h_{\vy}} } { ||\green{h_{\vx}} || \, ||\green{h_{\vy}} ||  }

$$


Le premier terme indique la similarité entre les paires positives. Le second terme est la fonction softmax entre toutes les paires négatives. Nous voulons minimiser cette fonction entière.

Remarquons qu'elle donne des poids différents aux différents échantillons négatifs. La paire négative qui a une forte similarité est poussée beaucoup plus fort que la paire négative avec une faible similarité parce qu'il y a la softmax. De plus, la mesure de similarité est ici le produit scalaire hermitien entre les deux représentations que l’on normalise pour éviter l'explosion du gradient. Ainsi, même si le vecteur est devenu long, le terme garantit qu'il s'agit d'un vecteur unitaire.

#### Banque mémoire

Comme déjà mentionné, ces modèles nécessitent des échantillons négatifs. Cependant, trouver des paires négatives devient difficile lorsque les espaces d’enchâssements deviennent grands.

Pour résoudre ce problème, SimCLR et MoCo utilisent des batchs de grande taille pour trouver les échantillons. La différence entre SimCLR et MoCo est la façon dont ils traitent la grande taille des batchs. SimCLR utilise une taille de batchs de 8192. Cependant, MoCo essaie de résoudre l'exigence d'une grande taille de batch sans en utiliser réellement une grâce à une banque mémoire. Au lieu d'utiliser des échantillons négatifs provenant uniquement du batch actuel, on en collecte dans les batchs précédents. Par exemple : pour un batch de taille 256, l'agrégation des 32 batchs précédents d'échantillons négatifs donne une taille de 8192. Cette méthode permet d'économiser de la mémoire et évite d'avoir à générer les échantillons négatifs encore et encore.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig3.png" height="75%" width="75%"/><br>
<b>Figure 7 :</b> Banque mémoire
</center>


Problème :
Parce que B est mis à jour à chaque pas de temps, le *backbone* est mis à jour à chaque pas de temps, alors après un certain temps, les vieux échantillons négatifs ne sont plus encore valides ce qui peut mener à une baisse des performances. Pour éviter cela, MoCo utilise un *backbone* avec *momentum* qui ralentit l’entraînement du *backbone* de droite. Dans ce cas, la différence entre le vieux *backbone* avec *momentum* et le nouveau *backbone* avec *momentum* n’est pas grande, conservant la validité des échantillons négatifs même après un certain temps.

<center>
<img src="{{site.baseurl}}/images/week15/15-1/1_fig4.png" height="75%" width="75%"/><br>
<b>Figure 8 :</b> Banque mémoire avec <i>backbone</i> avec <i>momentum</i>
</center>

$\vartheta_{t+1}$ (paramètres du *backbone* avec *momentum*) est l’exponentielle de la moyenne mobile de $\theta_{t}$. Le taux d’apprentissage de $\vartheta$ est $(1 -  m)* \eta$. Une grande valeur de $m$ rend $\vartheta_{t}$ stable. $m$ = 1 rend $\vartheta_{t}$ non entraîné. Si $m$ = 0, $\vartheta_{t+1}$ = $\theta_{t+1}$.

$$
\theta_{t+1} = \theta_{t} - \eta\Delta\theta_{t}  \\
\vartheta_{t+1} = m\vartheta_{t} + ( 1- m )\theta_{t+1}
$$

<div style="text-align: center">
$\theta:$ paramètres du *backbone*
</div>

<div style="text-align: center">
$\vartheta:$ paramètres du *backbone* avec *momentum*
</div>


#### Désavantages des méthodes contrastifs

En pratique, les méthodes contrastives nécessitent une énorme configuration pour fonctionner. Elles requièrent des techniques comme le partage de poids entre les branches, de la normalisation par batch, normalisation par caractéristiques, quantification de sortie, arrêt du gradient, banque mémoire, etc. Ces méthodes sont difficiles à analyser et sont instables sans toutes ces techniques.

